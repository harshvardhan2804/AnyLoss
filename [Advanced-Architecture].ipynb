{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"14MQ5TIwj_VA04qLX0pea4EEN8RvenMQ9","authorship_tag":"ABX9TyP6GLFOARyvO8eIaOWDf7+9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **ResNet with MNIST**"],"metadata":{"id":"0vw4837J7BQ0"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPhzQAvG6tTB","executionInfo":{"status":"ok","timestamp":1744876042664,"user_tz":-330,"elapsed":3823705,"user":{"displayName":"Harshvardhan _","userId":"01024503515961627297"}},"outputId":"86545628-3958-4de9-ff5b-0732df1ca5e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: ['keras_tensor']\n","Received: inputs=Tensor(shape=(None, 224, 224, 3))\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1726s\u001b[0m 7s/step - accuracy: 0.5127 - loss: 0.2967 - val_accuracy: 0.5080 - val_loss: 0.2564\n","Epoch 2/2\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1740s\u001b[0m 7s/step - accuracy: 0.5114 - loss: 0.2663 - val_accuracy: 0.5075 - val_loss: 0.2558\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: ['keras_tensor']\n","Received: inputs=Tensor(shape=(32, 224, 224, 3))\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 5s/step\n","Custom Accuracy      : 0.4928\n","Custom F-beta        : 0.9845\n","Custom Geometric Mean: 0.9117\n","Custom Balanced Acc. : 0.5002\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n","from sklearn.model_selection import train_test_split\n","\n","# ========== Load & Preprocess MNIST ==========\n","def load_mnist_images(file_path):\n","    with open(file_path, \"rb\") as f:\n","        _ = int.from_bytes(f.read(4), byteorder=\"big\")\n","        num_images = int.from_bytes(f.read(4), byteorder=\"big\")\n","        rows = int.from_bytes(f.read(4), byteorder=\"big\")\n","        cols = int.from_bytes(f.read(4), byteorder=\"big\")\n","        data = f.read()\n","    images = np.frombuffer(data, dtype=np.uint8).reshape((num_images, rows, cols, 1))\n","    return images.astype(\"float32\") / 255.0\n","\n","X = load_mnist_images(\"/content/drive/MyDrive/Colab Notebooks/Major-project-8th-sem/mnist.idx3-ubyte.csv\")\n","y = np.random.randint(0, 2, size=(X.shape[0], 1)).astype(\"float32\")\n","\n","# Reduce to 10k for speed/safety (optional)\n","X = X[:10000]\n","y = y[:10000]\n","\n","# Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ========== tf.data.Dataset with On-the-fly Resize ==========\n","AUTOTUNE = tf.data.AUTOTUNE\n","BATCH_SIZE = 32\n","\n","def preprocess(x, y):\n","    x = tf.image.resize(x, [224, 224])\n","    x = tf.image.grayscale_to_rgb(x)\n","    return x, y\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(preprocess).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n","test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(preprocess).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n","\n","# ========== Custom Metrics ==========\n","L = 73\n","\n","def ours_accu(y_true, y_pred):\n","    y_pred = 1 / (1 + tf.math.exp(-L * (y_pred - 0.5)))\n","    accu = (tf.cast(tf.shape(y_true)[0], tf.float32) - tf.reduce_sum(y_true) - tf.reduce_sum(y_pred) + 2 * tf.reduce_sum(y_true * y_pred)) / tf.cast(tf.shape(y_true)[0], tf.float32)\n","    return 1 - accu\n","\n","def ours_fbeta(y_true, y_pred, beta=1):\n","    y_pred = 1 / (1 + tf.math.exp(-L * (y_pred - 0.5)))\n","    numerator = (1 + beta**2) * tf.reduce_sum(y_true * y_pred)\n","    denominator = (beta**2) * tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","    return 1 - (numerator / (denominator + 1e-8))\n","\n","def ours_gmean(y_true, y_pred):\n","    y_pred = 1 / (1 + tf.math.exp(-L * (y_pred - 0.5)))\n","    syhy = tf.reduce_sum(y_true * y_pred)\n","    sy = tf.reduce_sum(y_true)\n","    yl = tf.cast(tf.shape(y_true)[0], tf.float32)\n","    gmean = tf.sqrt(syhy * (yl - tf.reduce_sum(y_pred) - sy + syhy) / (sy * (yl - sy) + 1e-8))\n","    return 1 - gmean\n","\n","def ours_baccu(y_true, y_pred):\n","    y_pred = 1 / (1 + tf.math.exp(-L * (y_pred - 0.5)))\n","    syhy = tf.reduce_sum(y_true * y_pred)\n","    sy = tf.reduce_sum(y_true)\n","    yl = tf.cast(tf.shape(y_true)[0], tf.float32)\n","    baccu = (yl * (syhy + sy) - sy * (tf.reduce_sum(y_pred) + sy)) / (2 * sy * (yl - sy) + 1e-8)\n","    return 1 - baccu\n","\n","# ========== Build ResNet50 Model ==========\n","base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","base_model.trainable = False  # Freeze base\n","\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(64, activation='relu')(x)\n","output = Dense(1)(x)  # Output logits\n","\n","model = Model(inputs=base_model.input, outputs=output)\n","model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse', metrics=['accuracy'])\n","\n","# ========== Train ==========\n","model.fit(train_ds, epochs=2, validation_data=test_ds)\n","\n","# ========== Predict & Evaluate ==========\n","# Get all test data for metric computation\n","X_test_resized = []\n","for x, _ in test_ds:\n","    X_test_resized.append(x)\n","X_test_resized = tf.concat(X_test_resized, axis=0)\n","\n","y_test_full = tf.concat([y for _, y in test_ds], axis=0)\n","y_pred_raw = model.predict(X_test_resized)\n","\n","print(f\"Custom Accuracy      : {ours_accu(y_test_full, y_pred_raw).numpy():.4f}\")\n","print(f\"Custom F-beta        : {ours_fbeta(y_test_full, y_pred_raw).numpy():.4f}\")\n","print(f\"Custom Geometric Mean: {ours_gmean(y_test_full, y_pred_raw).numpy():.4f}\")\n","print(f\"Custom Balanced Acc. : {ours_baccu(y_test_full, y_pred_raw).numpy():.4f}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"DlrEUL7v7F1-"},"execution_count":null,"outputs":[]}]}